{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "6_3_getting_started_with_distributed_data_parallel_jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxPc9L2RTEn2"
      },
      "source": [
        "# 「分散データ並列訓練入門」\n",
        "\n",
        "【原題】Getting Started with Distributed Data Parallel \n",
        "\n",
        "【原著】[Shen Li](https://mrshenli.github.io/)、[Joe Zhu](https://github.com/gunandrose4u)\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/intermediate/ddp_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID HCM事業部　櫻井 亮佑\n",
        "\n",
        "【日付】2020年11月20日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "前提知識\n",
        "- [PyTorch Distributed について](https://pytorch.org/tutorials/beginner/dist_overview.html)\n",
        "- [DistributedDataParallel API ドキュメント](https://pytorch.org/docs/master/generated/torch.nn.parallel.DistributedDataParallel.html)\n",
        "- [DistributedDataParallel について](https://pytorch.org/docs/master/notes/ddp.html)\n",
        "\n",
        "DistributedDataParallel (DDP) は、複数のマシン間で実行可能な、モジュールレベルのデータ並列化を実装可能にします。\n",
        "\n",
        "DDPを使用するアプリケーションでは、複数のプロセスを生成し、プロセスごとに単一のDDPインスタンスを作成する必要があります。\n",
        "\n",
        "DDP は [torch.distributed](https://pytorch.org/tutorials/intermediate/dist_tuto.html) パッケージの集合通信を使用して、勾配とバッファを同期できます。\n",
        "\n",
        "より具体的には、DDPでは `model.parameters()` で得られる各パラメータに対して自動微分のフックを登録し、対応する勾配がバックワードパスで計算されたときに、登録されたフックが起動します。\n",
        "\n",
        "そして、DDPはその信号を使用して、プロセス間の勾配の同期を実施します。\n",
        "\n",
        "詳細は、[DDPの設計について](https://pytorch.org/docs/master/notes/ddp.html) を参照してください。\n",
        "\n",
        "推奨されるDDPの使用方法は、複製したモデルを複数のデバイスに展開できる状態にし、複製したモデルごとに1つのプロセスを生成することです。\n",
        "\n",
        "DDPのプロセスは、同一のマシン、またはマシンを横断して存在することが可能ですが、プロセスをまたいでGPUデバイスを共有することはできません。\n",
        "\n",
        "本チュートリアルでは、基本的なDDPのユースケースから始め、その後モデルのチェックポイントやDDPとモデル並列の組み合わせなど、より発展的なユースケースを解説します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B-2FD7AC-Xc"
      },
      "source": [
        "**留意事項**\r\n",
        "\r\n",
        "本チュートリアルのコードは、8つのGPUを有するサーバー上で動作しますが、その他の環境にも適用できる内容になっています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5hB617VTEoH"
      },
      "source": [
        "## `DataParallel` と `DistributedDataParallel`\n",
        "\n",
        "内容に踏み込む前に、なぜ `DataParallel` ではなく、処理がより複雑になる`DistributedDataParallel` の使用を検討するのかを明確にしましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PJRD0VSTEoH"
      },
      "source": [
        "- `DataParallel` は、シングルプロセス・マルチスレッドでシングルマシンでのみ機能しますが、`DistributedDataParallel` では、マルチプロセスでシングルマシン訓練、マルチマシン訓練のどちらでも機能するためです。\n",
        "  通常、`DataParallel` は、スレッド間のGILの競合、イテレーション毎に複製するモデル、そして入力の分割と出力の収集によって発生するオーバーヘッドが原因となり、単一のマシン上であっても、`DistributedDataParallel` よりも遅くなります。\n",
        "- 前のチュートリアル（日本語訳6_2）で、モデルが大きすぎて単一のGPUに収まらない場合は、モデル並列を利用してモデルを複数のGPUに分割する必要があったことを思い出してください。\n",
        "  `DistributedDataParallel` は、モデル並列と共に動作できます。\n",
        "  一方、 `DataParallel` はモデル並列と共に使うことはできません。\n",
        "  DDPとモデル並列を組み合わせた場合、各DDPプロセスはモデル並列を使用し、すべてのプロセスが共同してデータ並列を使用することになります。\n",
        "- モデルをマルチマシンに展開する必要がある場合、またはユースケースがデータ並列化のパラダイムに収まらない場合は、[RPC API](https://pytorch.org/docs/stable/rpc.html) にて、より一般的な分散訓練のサポートについて参照できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIKk9TaSTEoH"
      },
      "source": [
        "## 基本的なユースケース\n",
        "\n",
        "DDPモジュールを作成するには、まずプロセスグループを適切にセットアップします。\n",
        "より詳細な内容については、「PyTorchで実装する分散アプリケーション」（日本語チュートリアル6_4） に記載があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKdtLhjFTEoI"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "\n",
        "def setup(rank, world_size):\n",
        "    if sys.platform == 'win32':\n",
        "        # Windowsプラットフォーム上では、Distribuedパッケージは\n",
        "        # Glooバックエンドの集合通信のみサポートしています。\n",
        "        # init_process_group内のinit_method パラメーターをローカルのファイルに設定してください。\n",
        "        # 例 init_method=\"file:///f:/libtmp/some_file\"\n",
        "        init_method=\"file:///{your local file path}\"\n",
        "\n",
        "        # プロセスグループの初期化\n",
        "        dist.init_process_group(\n",
        "            \"gloo\",\n",
        "            init_method=init_method,\n",
        "            rank=rank,\n",
        "            world_size=world_size\n",
        "        )\n",
        "    else:\n",
        "        os.environ['MASTER_ADDR'] = 'localhost'\n",
        "        os.environ['MASTER_PORT'] = '12355'\n",
        "\n",
        "        # プロセスグループの初期化\n",
        "        dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
        "\n",
        "def cleanup():\n",
        "    dist.destroy_process_group()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EP-ztoPTEoJ"
      },
      "source": [
        "それでは、簡易的なモジュールを作って、DDPでラップし、ダミーの入力データを与えてみましょう。\n",
        "\n",
        "なお、DDPは、モデルの状態を、ランク0のプロセスから、DDPのコンストラクター内に存在するその他すべてのプロセスにブロードキャストするため、異なるDDPプロセスが異なるモデルのパラメータの初期値から開始する点については考慮・心配する必要はありません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12uY4stxTEoJ"
      },
      "source": [
        "class ToyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.net1 = nn.Linear(10, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.net2 = nn.Linear(10, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net2(self.relu(self.net1(x)))\n",
        "\n",
        "\n",
        "def demo_basic(rank, world_size):\n",
        "    print(f\"Running basic DDP example on rank {rank}.\")\n",
        "    setup(rank, world_size)\n",
        "\n",
        "    # モデルを作成し、ランクidと共にGPUに移動\n",
        "    model = ToyModel().to(rank)\n",
        "    ddp_model = DDP(model, device_ids=[rank])\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = ddp_model(torch.randn(20, 10))\n",
        "    labels = torch.randn(20, 5).to(rank)\n",
        "    loss_fn(outputs, labels).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cleanup()\n",
        "\n",
        "\n",
        "def run_demo(demo_fn, world_size):\n",
        "    mp.spawn(demo_fn,\n",
        "             args=(world_size,),\n",
        "             nprocs=world_size,\n",
        "             join=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYG-qKrTEoK"
      },
      "source": [
        "上記のように、DDPは下位レベルの分散通信の詳細部分を隠ぺいし、ローカルモデルであるかのようなクリーンなAPIを提供しています（日本語訳注：通常の、並列処理出ない場合の実装とほぼ同じように実装を記載できます）。\n",
        "\n",
        "\n",
        "勾配を同期する通信はバックワードパスの最中に発生し、バックワードの演算処理と重複して行われます。\n",
        "\n",
        "そのため、`backward()` が返ってきたタイミングで、`param.grad` は同期化された勾配テンソルを既に含んでいます。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_AErLKOFiy0"
      },
      "source": [
        "基本的なユースケースであれば、DDPにはプロセスグループをセットアップするためのコードがもう少し必要になります。\r\n",
        "\r\n",
        "そして、より発展的なユースケースにDDPを適用する場合には、いくつか注意点があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skFOKyOmTEoK"
      },
      "source": [
        "## 歪んだ処理速度\n",
        "\n",
        "DDPでは、コンストラクター、フォワードパス、そしてバックワードパスが分散処理の同期ポイントになります。\n",
        "\n",
        "そして、異なるプロセスは同じ数の同期処理を起動し、同じ順序でこれらの同期ポイントに到達し、ほぼ同時に各同期ポイントに入ることが期待されています。\n",
        "\n",
        "このようにしなければ、速く行われるプロセスが早く到着し、出遅れたプロセスを待ってタイムアウトしてしまうかもしれません。\n",
        "\n",
        "したがって、ユーザーにはプロセス間でワークロードの分散を均等にする責任があります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Tn1EiXFuXP"
      },
      "source": [
        "ですが、処理速度の歪み、バラつきは、例えば、ネットワークの遅延、リソースの競合、または予測不能なワークロードの急増によって不可避的に発生することがあります。\r\n",
        "\r\n",
        "このような状況でのタイムアウトを避けるには、[init_process_group](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group) を呼び出す際に、十分な `timeout` 値を与えておくことです。\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LehdPMY_TEoL"
      },
      "source": [
        "## チェックポイントの保存と読み込み\n",
        "\n",
        "並列処理において、`torch.save` で訓練中にモジュールのチェックポイントを取得し、`torch.load` でチェックポイントから復元するのは、通常の使用方法の場合と共通しています。\n",
        "\n",
        "\n",
        "詳細は、[モデルの保存と読み込み](https://pytorch.org/tutorials/beginner/saving_loading_models.html) を参照してください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUBifO3bGGgY"
      },
      "source": [
        "DDPを使用する際の1つの最適化として、1つのプロセスのみでモデルを保存し、その後、すべてのプロセスで保存したモデルを読み込むことで、書き込みのオーバーヘッドを減らす手段があります。\r\n",
        "\r\n",
        "これは、すべてのプロセスが同じパラメーターから開始し、勾配はバックワードパスにおいて同期されるため、最適化関数がパラメーターに同じ値を設定し続けるはずである、という点で正しい考え方です。\r\n",
        "\r\n",
        "ただし、この最適化手法を用いる場合、モデルの保存が終了する前に、すべてのプロセスでモデルの読み込みが始まらないようにしてください。\r\n",
        "\r\n",
        "また、モジュールを読み込む際は、あるプロセスが他のデバイスに入り込まないように、`map_location` 引数を適切に与える必要もあります。\r\n",
        "`map_location` が抜けている場合、`torch.load` はまずモジュールをCPUに読み込み、その後モジュールが保存されたデバイスへと各パラメーターをコピーします。\r\n",
        "\r\n",
        "つまり、同一マシン上のすべてのプロセスが同じデバイスのセットを使用する状況に陥ってしまいます。\r\n",
        "\r\n",
        "より発展的な障害回復と柔軟性のあるサポートについては、[TorchElastic](https://pytorch.org/elastic) を参照してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UTs_Cv4TEoL"
      },
      "source": [
        "def demo_checkpoint(rank, world_size):\n",
        "    print(f\"Running DDP checkpoint example on rank {rank}.\")\n",
        "    setup(rank, world_size)\n",
        "\n",
        "    model = ToyModel().to(rank)\n",
        "    ddp_model = DDP(model, device_ids=[rank])\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
        "\n",
        "    CHECKPOINT_PATH = tempfile.gettempdir() + \"/model.checkpoint\"\n",
        "    if rank == 0:\n",
        "        # すべてのプロセスが同じランダムなパラメーターから始まっており、バックワードパスで勾配が同期されるため、\n",
        "        # すべてのプロセスが同じパラメーターを扱う必要があります。\n",
        "        # そして、これがモデルを一つのプロセスに保存すれば十分である理由です。\n",
        "        torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)\n",
        "\n",
        "    # プロセス0がモデルを保存した後にプロセス1がモデルを読み込めるように、barrier()を使用します。\n",
        "    dist.barrier()\n",
        "    # map_location を適切に設定します。\n",
        "    map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n",
        "    ddp_model.load_state_dict(\n",
        "        torch.load(CHECKPOINT_PATH, map_location=map_location))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = ddp_model(torch.randn(20, 10))\n",
        "    labels = torch.randn(20, 5).to(rank)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    loss_fn(outputs, labels).backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # DDPのバックワードパスにおいてAllReduceの処理がすでに同期処理として機能しているため、\n",
        "    # 下記のファイル削除処理をガードする目的で ist.barrier() を使用する必要はありません。\n",
        "    if rank == 0:\n",
        "        os.remove(CHECKPOINT_PATH)\n",
        "\n",
        "    cleanup()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSymiCzHTEoM"
      },
      "source": [
        "## DDPとモデル並列化の組み合わせ\n",
        "\n",
        "DDPは、マルチGPUモデル（モデル並列化）と共に使用することも可能です。\n",
        "\n",
        "マルチGPUモデルを包含したDDPは、膨大なデータ量で大規模なモデルを訓練する際に特に役立ちます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqbhzubSTEoM"
      },
      "source": [
        "class ToyMpModel(nn.Module):\n",
        "    def __init__(self, dev0, dev1):\n",
        "        super(ToyMpModel, self).__init__()\n",
        "        self.dev0 = dev0\n",
        "        self.dev1 = dev1\n",
        "        self.net1 = torch.nn.Linear(10, 10).to(dev0)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.net2 = torch.nn.Linear(10, 5).to(dev1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.dev0)\n",
        "        x = self.relu(self.net1(x))\n",
        "        x = x.to(self.dev1)\n",
        "        return self.net2(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_sNRH8MTEoM"
      },
      "source": [
        "マルチGPUモデルをDDPに与える際は、`device_ids` と `output_device` を設定してはいけません。\n",
        "\n",
        "入力データと出力データは、アプリケーション、またはモデルの `forward()` メソッドによって適切なデバイスに配置されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n88KL9d1TEoN"
      },
      "source": [
        "def demo_model_parallel(rank, world_size):\n",
        "    print(f\"Running DDP with model parallel example on rank {rank}.\")\n",
        "    setup(rank, world_size)\n",
        "\n",
        "    # このプロセスで使用するmp_modelとデバイスをセットアップ\n",
        "    dev0 = rank * 2\n",
        "    dev1 = rank * 2 + 1\n",
        "    mp_model = ToyMpModel(dev0, dev1)\n",
        "    ddp_mp_model = DDP(mp_model)\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # 出力は dev1 に行われる。\n",
        "    outputs = ddp_mp_model(torch.randn(20, 10))\n",
        "    labels = torch.randn(20, 5).to(dev1)\n",
        "    loss_fn(outputs, labels).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cleanup()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    if n_gpus < 8:\n",
        "        print(f\"Requires at least 8 GPUs to run, but got {n_gpus}.\")\n",
        "    else:\n",
        "        run_demo(demo_basic, 8)\n",
        "        run_demo(demo_checkpoint, 8)\n",
        "        run_demo(demo_model_parallel, 4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}